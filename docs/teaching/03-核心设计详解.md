# 教案3：核心设计详解

---

## 【核心1】意图分析：IntentAnalyzer 如何判断用户想生成什么

### 设计思路

用户输入是自然语言（中文），我们需要从中提取结构化信息。两种方案：

| 方案 | 优点 | 缺点 |
|------|------|------|
| 规则引擎（正则/关键词匹配）| 快、便宜、可控 | 无法处理复杂表达 |
| LLM 解析 | 理解自然语言、处理模糊表达 | 需要 API 调用、有延迟 |

我们选择：**LLM **，用便宜的 gpt-4o-mini 做解析。

### 关键代码

**系统提示词**（定义 LLM 的解析规则）：

```java
// IntentAnalyzer.java
private static final String SYSTEM_PROMPT = """
    你是一个AIGC意图解析器。你的任务是分析用户的自然语言请求，提取结构化信息。
    
    ## 你需要识别的信息：
    
    ### 1. 内容类型 (contentType)
    - IMAGE: 图片生成、图片编辑、风格转换
    - VIDEO: 视频生成、图片变视频
    - AUDIO: 音乐生成、语音合成
    
    ### 2. 意图场景 (intent)
    - text_to_image / image_to_image / text_to_video / image_to_video / text_to_audio
    
    ### 3. 技术参数提取
    - 图片：aspectRatio, imageSize, style
    - 视频：aspectRatio, resolution, duration, quality, withAudio
    - 音频：type(tts/music), voice, bpm, mood
    
    ### 4. 清洗后的提示词 (cleanPrompt)
    从原始输入中移除所有技术参数描述，只保留创意内容。
    例如："帮我生成一个4K竖屏视频，一只猫在跳舞" → "一只猫在跳舞"
    
    ## 输出格式：严格JSON
    """;
```

**调用流程**：

```java
// IntentAnalyzer.java - analyze() 方法
public AnalyzedIntent analyze(String userInput, boolean hasReferenceImages) {
    // 1. 检查 OneRouter 是否配置
    if (!aigcProperties.isOneRouterConfigured()) {
        throw new RuntimeException("OneRouter 未配置！");
    }
    
    // 2. 构建 OpenAI 兼容请求（OneRouter 兼容 OpenAI API 格式）
    Map<String, Object> requestBody = Map.of(
        "model", "gpt-4o-mini",
        "temperature", 0.1,          // 低温度 = 更确定的输出
        "messages", List.of(
            Map.of("role", "system", "content", SYSTEM_PROMPT),
            Map.of("role", "user", "content", buildUserMessage(userInput, hasReferenceImages))
        )
    );
    
    // 3. 调用 OneRouter API
    HttpHeaders headers = new HttpHeaders();
    headers.setBearerAuth(oneRouterConfig.getApiKey());
    ResponseEntity<Map> response = restTemplate.exchange(apiUrl, HttpMethod.POST, entity, Map.class);
    
    // 4. 从 LLM 返回中提取 JSON（处理 markdown 代码块包裹的情况）
    String jsonResponse = extractJsonFromResponse(response.getBody());
    AnalyzedIntent intent = objectMapper.readValue(jsonResponse, AnalyzedIntent.class);
    
    // 5. 根据参考图片调整意图
    if (hasReferenceImages) {
        if (intent.getContentType() == ContentType.IMAGE) intent.setIntent("image_to_image");
        if (intent.getContentType() == ContentType.VIDEO) intent.setIntent("image_to_video");
    }
    
    return intent;
}
```

### 要点

1. **Prompt Engineering**：系统提示词的设计决定了解析质量，注意参数枚举值、默认值和示例
2. **temperature = 0.1**：意图解析需要确定性，不需要创造性
3. **成本意识**：gpt-4o-mini ($0.15/1M tokens) vs Gemini Pro ($7/1M tokens)，差 46 倍
4. **容错处理**：LLM 返回可能被 markdown 代码块包裹，需要清洗

---

## 【核心2】智能路由：RoutingAgent 如何选择正确的 Provider

### 设计思路

RoutingAgent 是整个系统的"大脑"，它不直接生成内容，而是编排三个组件：

```
RoutingAgent.analyze()
    ├── intentAnalyzer.analyze()    →  得到 AnalyzedIntent
    ├── selectOptimalModel()        →  选择最优模型
    └── promptEnhancer.enhance()    →  优化提示词
```

### 关键代码：模型选择策略

```java
// RoutingAgent.java
private String selectOptimalModel(AnalyzedIntent intent) {
    return switch (intent.getContentType()) {
        case IMAGE -> selectImageModel(intent);
        case VIDEO -> selectVideoModel(intent);
        case AUDIO -> selectAudioModel(intent);
        case TEXT -> throw new UnsupportedOperationException("不支持纯文本生成");
    };
}

// 图片模型选择：根据分辨率需求
private String selectImageModel(AnalyzedIntent intent) {
    var imageParams = intent.getEffectiveImageParams();
    
    // 2K/4K 高分辨率 → 使用 Gemini 3 Pro（更强但更贵）
    if ("2K".equals(imageParams.getImageSize()) || "4K".equals(imageParams.getImageSize())) {
        return "gemini-3-pro-image-preview";
    }
    // 默认 → 使用 Gemini 2.5 Flash（快速便宜）
    return aigcProperties.getImage().getGoogle().getModel();
}

// 视频模型选择：根据质量偏好
private String selectVideoModel(AnalyzedIntent intent) {
    var videoParams = intent.getEffectiveVideoParams();
    String baseModel = aigcProperties.getVideo().getGoogle().getModel();
    
    // 用户说"快一点" → fast 模型（$0.15/秒）
    if ("fast".equals(videoParams.getQuality())) {
        return baseModel.replace("-generate-", "-fast-generate-");
    }
    // 用户说"高质量" → standard 模型（$0.40/秒）
    if ("standard".equals(videoParams.getQuality())) {
        return baseModel.replace("-fast-generate-", "-generate-");
    }
    return baseModel;
}
```

### 关键代码：执行生成

```java
// RoutingAgent.java
public GenerationResult executeGeneration(AigcTask task) {
    // 根据内容类型路由到对应的 Provider
    GenerationResult result = switch (task.getContentType()) {
        case IMAGE -> providerRouter.getImageProvider().generate(task);
        case VIDEO -> providerRouter.getVideoProvider().generate(task);
        case AUDIO -> providerRouter.getAudioProvider().generate(task);
        case TEXT -> throw new UnsupportedOperationException("不支持纯文本生成");
    };
    return result;
}
```

### 要点

1. **策略模式的应用**：switch 表达式根据内容类型分发，每种类型有独立的选择逻辑
2. **Java 17 新特性**：switch 表达式（带箭头和返回值），比传统 switch-case 简洁
3. **配置驱动**：默认模型从 YAML 配置读取，代码中只处理"升级/降级"逻辑

---

## 【核心3】图片生成：GoogleImageProvider 调用 Gemini API

### 设计思路

图片生成是最"直接"的：发送请求 → 等待响应 → 解析图片。但要注意：
- 支持文生图和图生图（有参考图片时）
- 使用 OkHttp 而非 RestTemplate（OkHttp 对二进制数据处理更好）
- 图片以 Base64 返回，需要解码保存

### 关键代码：构建请求

```java
// GoogleImageProvider.java
private String buildRequestBody(String prompt, String aspectRatio, 
                                 String model, List<String> referenceImages) {
    ObjectNode root = objectMapper.createObjectNode();
    
    // 1. contents 部分
    ArrayNode contents = root.putArray("contents");
    ObjectNode content = contents.addObject();
    ArrayNode parts = content.putArray("parts");
    
    // 文本提示
    parts.addObject().put("text", prompt);
    
    // 参考图片（图生图场景）
    if (referenceImages != null) {
        for (String imageData : referenceImages) {
            ObjectNode imagePart = createImagePart(imageData);  // Base64 → inlineData
            if (imagePart != null) parts.add(imagePart);
        }
    }
    
    // 2. generationConfig 部分
    ObjectNode generationConfig = root.putObject("generationConfig");
    ArrayNode modalities = generationConfig.putArray("responseModalities");
    modalities.add("TEXT");    // 返回文本描述
    modalities.add("IMAGE");   // 返回图片
    
    // 宽高比配置
    ObjectNode imageConfig = generationConfig.putObject("imageConfig");
    imageConfig.put("aspectRatio", aspectRatio);  // "16:9", "9:16", "1:1" 等
    
    return objectMapper.writeValueAsString(root);
}
```

### 关键代码：发送请求和解析响应

```java
// GoogleImageProvider.java - generate() 核心流程
public GenerationResult generate(AigcTask task) {
    // 1. 构建 URL：直连 Google API
    String url = googleConfig.getBaseUrl() + "/v1beta/models/" + model 
                 + ":generateContent?key=" + apiKey;
    
    // 2. 发送请求（OkHttp）
    Request httpRequest = new Request.Builder()
            .url(url)
            .post(RequestBody.create(requestBody, JSON_MEDIA_TYPE))
            .build();
    
    Response response = httpClient.newCall(httpRequest).execute();
    
    // 3. 解析响应：从 candidates[0].content.parts 中提取图片
    // Gemini 返回格式：
    // { "candidates": [{ "content": { "parts": [
    //     { "text": "..." },              ← 文本描述
    //     { "inlineData": {               ← 图片数据
    //         "mimeType": "image/png",
    //         "data": "base64..."
    //     }}
    // ]}}]}
    List<GeneratedImage> images = parseResponse(responseBody);
    
    // 4. Base64 解码 → 保存到本地文件系统
    String url = saveImageToLocal(base64Data, mimeType, taskId);
    // 保存到 uploads/images/{taskId}.png
    // 返回 URL: http://localhost:10003/files/images/{taskId}.png
}
```

### 要点

1. **Gemini API 格式**：`contents.parts` 数组可以混合文本和图片，`responseModalities` 控制返回类型
2. **图生图**：和文生图的区别仅在于 parts 中多了 `inlineData`（Base64 图片）
3. **代理配置**：国内访问 Google API 需要代理，OkHttp 的 `builder.proxy()` 实现
4. **文件存储**：生成的图片保存到 `uploads/images/`，通过 Spring 静态资源映射对外提供访问

---

## 【核心4】视频生成：GoogleVideoProvider 调用 Veo API

### 设计思路

视频生成和图片生成最大的区别：**视频生成是异步的**。

Veo API 使用 `predictLongRunning` 模式：
1. 发送生成请求 → 返回操作 ID（operation name）
2. 轮询操作状态 → 等待 `done: true`
3. 下载生成的视频 → 保存到本地

### 关键代码：发送异步请求

```java
// GoogleVideoProvider.java
public GenerationResult generate(AigcTask task) {
    // 1. 使用 predictLongRunning 端点（不是 generateContent）
    String url = GEMINI_API_BASE + "/" + model + ":predictLongRunning?key=" + apiKey;
    
    // 2. 请求体格式和图片不同
    // {
    //   "instances": [{ 
    //     "prompt": "一只猫在跳舞",
    //     "image": { "bytesBase64Encoded": "...", "mimeType": "image/jpeg" }  ← 图生视频才有
    //   }],
    //   "parameters": { "aspectRatio": "16:9", "durationSeconds": 8 }
    // }
    String requestBody = buildVideoRequestBody(prompt, config, referenceImages);
    
    // 3. 发送请求 → 返回操作 ID
    Response response = httpClient.newCall(httpRequest).execute();
    String operationName = responseJson.get("name").asText();
    
    // 4. 轮询等待完成
    String videoUrl = pollForVideoCompletion(operationName, apiKey, taskId);
}
```

### 关键代码：轮询等待

```java
// GoogleVideoProvider.java
private static final int MAX_POLL_ATTEMPTS = 30;    // 最多 30 次
private static final long POLL_INTERVAL_MS = 10000;  // 每 10 秒一次 → 最多等 5 分钟

private String pollForVideoCompletion(String operationName, String apiKey, String taskId) {
    String pollUrl = "https://generativelanguage.googleapis.com/v1beta/" 
                     + operationName + "?key=" + apiKey;
    
    for (int attempt = 0; attempt < MAX_POLL_ATTEMPTS; attempt++) {
        Response response = httpClient.newCall(new Request.Builder().url(pollUrl).get().build()).execute();
        JsonNode json = objectMapper.readTree(response.body().string());
        
        boolean done = json.has("done") && json.get("done").asBoolean();
        
        if (done) {
            // 检查错误
            if (json.has("error")) {
                throw new RuntimeException("视频生成失败: " + json.get("error").get("message").asText());
            }
            // 解析视频 URI → 下载到本地
            return parseDirectVideoResponse(json.get("response"), taskId);
        }
        
        Thread.sleep(POLL_INTERVAL_MS);  // 等 10 秒再查
    }
    
    throw new RuntimeException("视频生成超时");
}
```

### 关键代码：下载视频

```java
// GoogleVideoProvider.java
private String downloadAndSaveVideo(String videoUri, String taskId) {
    // Veo 返回的 URI 需要带上 API Key 才能下载
    String downloadUrl = videoUri + "?key=" + apiKey;
    
    Response response = httpClient.newCall(new Request.Builder().url(downloadUrl).get().build()).execute();
    byte[] videoBytes = response.body().bytes();
    
    // 保存到 uploads/videos/{taskId}.mp4
    Path filePath = Paths.get(basePath, "videos", taskId + ".mp4");
    Files.write(filePath, videoBytes);
    
    // 返回访问 URL
    return urlPrefix + "/videos/" + taskId + ".mp4";
}
```

### 图生视频 vs 文生视频

唯一区别在请求体：

```json
// 文生视频
{ "instances": [{ "prompt": "一只猫在跳舞" }], "parameters": { ... } }

// 图生视频：多了 image 字段
{ "instances": [{ 
    "prompt": "让这张图动起来",
    "image": { "bytesBase64Encoded": "...", "mimeType": "image/jpeg" }
  }], "parameters": { ... } }
```

### 要点

1. **Long Running Operation 模式**：很多 AI API 都采用这种异步模式（Google、OpenAI、Stability）
2. **轮询策略**：10 秒间隔是经验值，太频繁浪费请求，太慢用户体验差
3. **超时控制**：MAX_POLL_ATTEMPTS × POLL_INTERVAL_MS = 最大等待时间，需要合理设置
4. **OkHttp 超时**：`readTimeout(600s)` 比普通接口长很多，因为需要等待视频生成

---

## 【核心5】任务管理：异步任务状态轮询机制

### 设计思路

整个任务管理围绕两张表和四种状态：

```
AigcTask 表                              AigcAsset 表
┌──────────────────────────┐             ┌──────────────────────────┐
│ taskId (UUID)            │             │ assetId (UUID)           │
│ prompt (用户输入)         │    成功时    │ contentType              │
│ optimizedPrompt (增强后)  │ ──────────> │ url (生成结果URL)         │
│ contentType (IMAGE/...)  │    关联      │ thumbnailUrl             │
│ model (选定的模型)        │             │ prompt                   │
│ status (任务状态)         │             │ model                    │
│ progress (0-100)         │             │ isPublished (发到广场)     │
│ errorMessage             │             │ createdAt                │
│ assetId (关联资产)        │             └──────────────────────────┘
│ createdAt / updatedAt    │
└──────────────────────────┘

状态流转：
PENDING → PROCESSING → COMPLETED (成功)
PENDING → PROCESSING → FAILED    (失败)
```

### 关键代码：任务创建和异步执行

```java
// AigcServiceImpl.java
@Transactional
public GenerateResponse generate(GenerateRequest request) {
    // 1. Agent 分析（同步，1-3秒）
    AgentAnalysis analysis = routingAgent.analyze(request);
    
    // 2. 创建任务记录（PENDING）
    AigcTask task = new AigcTask();
    task.setTaskId(IdUtils.uuid());
    task.setPrompt(request.getPrompt());
    task.setOptimizedPrompt(analysis.getOptimizedPrompt());
    task.setContentType(analysis.getContentType());
    task.setModel(analysis.getSelectedModel());
    task.setStatus(TaskStatus.PENDING);
    taskRepository.save(task);
    
    // 3. 异步执行（不阻塞当前请求）
    executeGenerationAsync(task.getTaskId());
    
    // 4. 立即返回 taskId + Agent 分析结果
    return GenerateResponse.builder()
            .taskId(task.getTaskId())
            .status(TaskStatus.PENDING)
            .agentAnalysis(analysis)
            .build();
}
```

### 关键代码：异步执行线程

```java
// AigcServiceImpl.java
@Async  // Spring 异步注解，在独立线程池中执行
public void executeGenerationAsync(String taskId) {
    try {
        AigcTask task = taskRepository.findByTaskId(taskId).orElseThrow(...);
        
        // 更新为处理中
        task.setStatus(TaskStatus.PROCESSING);
        task.setProgress(10);
        taskRepository.save(task);
        
        // 调用 Provider 生成（这里会阻塞，等图片/视频生成完成）
        GenerationResult result = routingAgent.executeGeneration(task);
        
        if (result.isSuccess()) {
            // 生成成功 → 保存资产
            AigcAsset asset = new AigcAsset();
            asset.setAssetId(IdUtils.uuid());
            asset.setUrl(result.getUrl());
            asset.setContentType(task.getContentType());
            assetRepository.save(asset);
            
            task.setStatus(TaskStatus.COMPLETED);
            task.setProgress(100);
            task.setAssetId(asset.getAssetId());
        } else {
            // 生成失败 → 不保存资产
            task.setStatus(TaskStatus.FAILED);
            task.setErrorMessage(result.getErrorMessage());
        }
        taskRepository.save(task);
        
    } catch (Exception e) {
        // 异常 → 更新为失败
        taskRepository.findByTaskId(taskId).ifPresent(task -> {
            task.setStatus(TaskStatus.FAILED);
            task.setErrorMessage(e.getMessage());
            taskRepository.save(task);
        });
    }
}
```

### 关键代码：前端轮询查询

```java
// AigcServiceImpl.java
public TaskStatusResponse getTaskStatus(String taskId) {
    AigcTask task = taskRepository.findByTaskId(taskId).orElseThrow(...);
    
    TaskStatusResponse response = TaskStatusResponse.builder()
            .taskId(task.getTaskId())
            .status(task.getStatus())
            .progress(task.getProgress())
            .errorMessage(task.getErrorMessage())
            .build();
    
    // 任务完成时，关联查询生成结果
    if (task.getStatus() == TaskStatus.COMPLETED && task.getAssetId() != null) {
        assetRepository.findByAssetId(task.getAssetId()).ifPresent(asset -> {
            response.setResult(GenerationResult.builder()
                    .assetId(asset.getAssetId())
                    .url(asset.getUrl())        // 图片/视频/音频的访问 URL
                    .contentType(asset.getContentType())
                    .build());
        });
    }
    
    return response;
}
```

### API 接口总览

```
POST /api/aigc/generate          →  创建任务，返回 taskId
GET  /api/aigc/task/{taskId}     →  查询任务状态（轮询用）
GET  /api/aigc/models            →  获取可用模型列表
GET  /api/aigc/gallery           →  灵感广场作品列表
POST /api/aigc/gallery/save      →  发布作品到广场
GET  /api/aigc/assets            →  我的资产列表
DELETE /api/aigc/assets/{id}     →  删除资产
```

### 要点

1. **@Async 注意事项**：需要 `@EnableAsync` 开启，异步方法不能在同一个类中直接调用（会失效）
2. **事务边界**：`generate()` 方法用 `@Transactional`，但 `executeGenerationAsync()` 在新线程中需要独立事务
3. **幂等设计**：taskId 使用 UUID，前端可以安全重试轮询
4. **错误处理**：异步线程中的异常不会抛到主线程，必须在 try-catch 中更新任务状态
5. **资产分离**：Task 是临时的（过程状态），Asset 是永久的（生成结果），分表存储
